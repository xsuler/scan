import streamlit as st
import pandas as pd
import traceback
import requests
import time
import numpy as np
from solders.pubkey import Pubkey
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Configuration
JUPITER_TOKEN_LIST = "https://token.jup.ag/all"
JUPITER_QUOTE_API = "https://quote-api.jup.ag/v6/quote"
JUPITER_PRICE_API = "https://api.jup.ag/price/v2"
USDC_MINT = "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"
UI_REFRESH_INTERVAL = 0.01
ROW_HEIGHT = 35
HEADER_HEIGHT = 50

class TokenAnalyzer:
    def __init__(self):
        self.session = requests.Session()
        retries = Retry(total=3, backoff_factor=1, status_forcelist=[502, 503, 504])
        self.session.mount('https://', HTTPAdapter(max_retries=retries))
        self.debug_info = []

    def get_all_tokens(self, strict_checks=True):
        self.debug_info = []
        try:
            response = self.session.get(JUPITER_TOKEN_LIST, timeout=15)
            response.raise_for_status()
            tokens = response.json()
            return [t for t in tokens if self.validate_token(t, strict_checks)]
        except Exception as e:
            st.error(f"Token fetch error: {str(e)}")
            return []

    def validate_token(self, token, strict_checks):
        debug_entry = {
            'symbol': token.get('symbol', 'Unknown'),
            'address': token.get('address', ''),
            'valid': False,
            'reasons': []
        }

        try:
            if not Pubkey.from_string(token.get('address', '')):
                debug_entry['reasons'].append('Invalid address')
                return False

            required_fields = ['symbol', 'name', 'decimals', 'logoURI']
            for field in required_fields:
                if not token.get(field):
                    debug_entry['reasons'].append(f'Missing {field}')
                    return False

            checks = [
                ('tags', lambda: "community" in token.get('tags', [])),
                ('chain', lambda: token.get('chainId') == 101)
            ]

            for check_name, check_func in checks:
                if not check_func():
                    debug_entry['reasons'].append(f'Failed {check_name}')
                    if strict_checks: return False

            debug_entry['valid'] = True
            return True
        except Exception as e:
            debug_entry['reasons'].append(f'Validation error: {str(e)}')
            return False
        finally:
            self.debug_info.append(debug_entry)

    def safe_float(self, value, default=0.0):
        try:
            return float(value) if value not in [None, np.nan, ''] else default
        except:
            return default

    def analyze_token(self, token):
        try:
            price_data = self.get_token_price_data(token)
            analysis = {
                'symbol': token.get('symbol', 'Unknown'),
                'address': token['address'],
                'price': self.safe_float(price_data.get('price', 0)),
                'price_type': price_data.get('type', 'N/A'),
                'liquidity': self.calculate_liquidity_score(token),
                'confidence': price_data.get('confidence', 'medium'),
                'buy_price': self.safe_float(price_data.get('buy_price', 0)),
                'sell_price': self.safe_float(price_data.get('sell_price', 0)),
                'price_impact_10': self.safe_float(price_data.get('price_impact_10', 0)),
                'price_impact_100': self.safe_float(price_data.get('price_impact_100', 0)),
                'explorer': f"https://solscan.io/token/{token['address']}",
            }
            
            analysis['score'] = self.calculate_score(analysis)
            return analysis
        except Exception as e:
            st.error(f"Analysis failed for {token.get('symbol')}: {str(e)}")
            return None

    def calculate_liquidity_score(self, token):
        try:
            decimals = token.get('decimals', 9)
            amount = int(1000 * (10 ** decimals))
            response = self.session.get(
                f"{JUPITER_QUOTE_API}?inputMint={token['address']}&outputMint={USDC_MINT}&amount={amount}",
                timeout=15
            )
            response.raise_for_status()
            quote = response.json()
            price_impact = self.safe_float(quote.get('priceImpactPct', 1))
            return max(0.0, 100.0 - (price_impact * 10000))
        except Exception as e:
            print(f"Liquidity calculation error: {str(e)}")
            return 0.0

    def calculate_score(self, analysis):
        try:
            liquidity = analysis['liquidity'] / 100
            
            price = analysis['price']
            buy_price = analysis['buy_price']
            sell_price = analysis['sell_price']
            
            if price <= 0 or (buy_price == 0 and sell_price == 0):
                price_stability = 0.0
            else:
                spread = abs(buy_price - sell_price)
                price_stability = 1 - (spread / price) if price != 0 else 0
                price_stability = np.clip(price_stability, 0, 1)
            
            impact_10 = analysis['price_impact_10']
            impact_100 = analysis['price_impact_100']
            avg_impact = (impact_10 + impact_100) / 2
            market_depth = 1 - np.clip(avg_impact, 0, 1)
            
            weights = {
                'liquidity': 0.4,
                'price_stability': 0.35,
                'market_depth': 0.25
            }
            
            penalties = 0
            if price <= 0:
                penalties += 0.3
            if analysis['liquidity'] <= 0:
                penalties += 0.2
            if analysis['confidence'] != 'high':
                penalties += 0.1
                
            raw_score = (
                weights['liquidity'] * liquidity +
                weights['price_stability'] * price_stability +
                weights['market_depth'] * market_depth
            )
            
            final_score = (raw_score - penalties) * 100
            return final_score  # ç§»é™¤åˆ†æ•°é™åˆ¶
            
        except KeyError as e:
            print(f"Missing key in score calculation: {str(e)}")
            return 0.0

    def get_token_price_data(self, token):
        try:
            response = self.session.get(
                f"{JUPITER_PRICE_API}?ids={token['address']}&showExtraInfo=true",
                timeout=15
            )
            response.raise_for_status()
            data = response.json()
            price_data = data.get('data', {}).get(token['address'], {})
            
            return {
                'price': self.safe_float(price_data.get('price', 0)),
                'type': price_data.get('type', 'N/A'),
                'confidence': price_data.get('extraInfo', {}).get('confidenceLevel', 'medium'),
                'buy_price': self.safe_float(price_data.get('extraInfo', {}).get('quotedPrice', {}).get('buyPrice', 0)),
                'sell_price': self.safe_float(price_data.get('extraInfo', {}).get('quotedPrice', {}).get('sellPrice', 0)),
                'price_impact_10': self.safe_float(price_data.get('extraInfo', {}).get('depth', {}).get('sellPriceImpactRatio', {}).get('depth', {}).get('10', 0)),
                'price_impact_100': self.safe_float(price_data.get('extraInfo', {}).get('depth', {}).get('sellPriceImpactRatio', {}).get('depth', {}).get('100', 0)),
            }
        except Exception as e:
            st.error(f"Price data error: {str(e)}")
            return {}

class AnalysisManager:
    def __init__(self, analyzer):
        self.analyzer = analyzer
        self.init_session()
        
    def init_session(self):
        defaults = {
            'analysis': {
                'running': False,
                'progress': 0,
                'params': None,
                'metrics': {'start_time': None, 'speed': 0},
                'current_index': 0,
                'current_token': None,
            },
            'live_results': pd.DataFrame()
        }
        for key, val in defaults.items():
            st.session_state.setdefault(key, val)

    def start_analysis(self, tokens, params):
        st.session_state.analysis = {
            'running': True,
            'progress': 0,
            'params': params,
            'metrics': {
                'start_time': time.time(),
                'speed': 0,
                'total_tokens': len(tokens)
            },
            'current_index': 0,
            'tokens': tokens,
            'current_token': None
        }
        st.session_state.live_results = pd.DataFrame()

    def process_tokens(self):
        if not st.session_state.analysis['running']:
            return

        idx = st.session_state.analysis['current_index']
        tokens = st.session_state.analysis['tokens']
        
        if idx < len(tokens):
            token = tokens[idx]
            analysis = self.analyzer.analyze_token(token)
            
            if analysis is not None:
                st.session_state.analysis['current_token'] = token
                new_row = pd.DataFrame([analysis])
                st.session_state.live_results = pd.concat(
                    [st.session_state.live_results, new_row],
                    ignore_index=True
                )

            st.session_state.analysis['progress'] = idx + 1
            st.session_state.analysis['current_index'] += 1
            st.session_state.analysis['metrics']['speed'] = (idx + 1) / (
                time.time() - st.session_state.analysis['metrics']['start_time']
            )
            
            time.sleep(UI_REFRESH_INTERVAL)
            st.rerun()
        else:
            self.finalize_analysis()

    def finalize_analysis(self):
        st.session_state.analysis['running'] = False
        if st.session_state.live_results.empty:
            st.warning("No qualified tokens found during analysis")

class UIManager:
    def __init__(self, analyzer):
        self.analyzer = analyzer
        self.manager = AnalysisManager(analyzer)
        self.inject_responsive_css()

    def inject_responsive_css(self):
        """å“åº”å¼å¸ƒå±€é€‚é…"""
        st.markdown("""
        <style>
            /* å¼ºåˆ¶ä¾§è¾¹æ å…¨å±æ˜¾ç¤º */
            section[data-testid="stSidebar"] {
                width: 100% !important;
                min-width: 100% !important;
                transform: translateX(0) !important;
                z-index: 999999;
            }

            /* éšè—æŠ˜å æŒ‰é’® */
            [data-testid="collapsedControl"] {
                display: none !important;
            }

            /* ä¸»å†…å®¹åŒºé€‚é… */
            .main .block-container {
                padding-top: 2rem;
                position: relative;
                z-index: 1;
            }

            /* ç§»åŠ¨ç«¯æŒ‰é’®é€‚é… */
            @media (max-width: 768px) {
                /* æŒ‰é’®å®¹å™¨ */
                div.stButton > button {
                    width: 100% !important;
                    margin: 8px 0 !important;
                }
                
                /* ä¸¤åˆ—å¸ƒå±€æ”¹ä¸ºå †å  */
                div[data-testid="column"] {
                    flex: 0 0 100% !important;
                    width: 100% !important;
                }
                
                /* è¡¨æ ¼ä¼˜åŒ– */
                div[data-testid="stDataFrame"] {
                    font-size: 14px;
                }
            }

            /* æ¡Œé¢ç«¯æŒ‰é’®é—´è· */
            @media (min-width: 769px) {
                div[data-testid="stHorizontalBlock"] {
                    gap: 1rem;
                }
            }
        </style>
        """, unsafe_allow_html=True)

    def render_sidebar(self):
        with st.sidebar:
            st.title("ğŸª™ Solana Token Analyzer")
            st.image("https://jup.ag/svg/jupiter-logo.svg", width=200)
            
            with st.expander("âš™ï¸ Control Panel", expanded=True):
                params = {
                    'strict_mode': st.checkbox("Strict Validation", True),
                    'live_sorting': st.checkbox("Real-time Sorting", True)
                }

            # æŒ‰é’®å®¹å™¨ä½¿ç”¨å¼¹æ€§å¸ƒå±€
            with st.container():
                cols = st.columns([1, 1, 1])  # ä¸‰åˆ—å¸ƒå±€
                with cols[0]:
                    if st.button("ğŸš€ Start", use_container_width=True, help="å¼€å§‹åˆ†æ"):
                        self.start_analysis(params)
                with cols[1]:
                    if st.button("â¹ Stop", use_container_width=True, help="åœæ­¢åˆ†æ"):
                        st.session_state.analysis['running'] = False
                with cols[2]:
                    if st.button("ğŸ§¹ Clear", use_container_width=True, help="æ¸…é™¤ç»“æœ"):
                        st.session_state.live_results = pd.DataFrame()
                        st.rerun()

            if st.session_state.analysis.get('running', False):
                self.render_progress()
                self.render_current_token()

            if not st.session_state.live_results.empty:
                st.divider()
                self.render_sidebar_results()

    def render_progress(self):
        analysis = st.session_state.analysis
        metrics = analysis['metrics']
        progress = analysis['progress'] / metrics['total_tokens']
        
        st.progress(min(progress, 1.0), text="Analysis Progress")
        cols = st.columns(3)
        with cols[0]:
            st.metric("Processed", f"{analysis['progress']}/{metrics['total_tokens']}")
        with cols[1]:
            st.metric("Speed", f"{(analysis['metrics']['speed']):.1f} tkn/s")
        with cols[2]:
            st.metric("Found", f"{len(st.session_state.live_results)}")

    def render_current_token(self):
        current_token = st.session_state.analysis.get('current_token')
        if not current_token:
            return

        with st.expander("ğŸ” Current Token", expanded=True):
            st.subheader(current_token.get('symbol', 'Unknown'))
            st.caption(f"`{current_token.get('address', '')[:12]}...`")
            st.write(f"**Chain:** Solana Mainnet")
            st.write(f"**Decimals:** {current_token.get('decimals', 'N/A')}")

    def start_analysis(self, params):
        tokens = self.analyzer.get_all_tokens(params['strict_mode'])
        if tokens:
            self.manager.start_analysis(tokens, params)
            self.manager.process_tokens()
        else:
            st.error("No tokens found matching criteria")

    def calculate_table_height(self, df):
        num_rows = len(df)
        base_height = HEADER_HEIGHT + num_rows * ROW_HEIGHT
        return min(base_height, 600)

    def render_sidebar_results(self):
        st.subheader("ğŸ“Š Live Results")
        df = st.session_state.live_results
        
        # åŠ¨æ€æ’åºå’Œåˆ—é¡ºåºè°ƒæ•´
        sorted_df = df.sort_values(by='score', ascending=False)
        
        # è°ƒæ•´åˆ—é¡ºåºï¼ˆscoreç¬¬ä¸€åˆ—ï¼‰
        sorted_df = sorted_df[['score', 'symbol', 'price', 'liquidity', 'confidence', 'explorer']]

        table_height = self.calculate_table_height(sorted_df)

        st.data_editor(
            sorted_df,
            column_config={
                'score': st.column_config.NumberColumn(
                    'Score',
                    help="ç»¼åˆè¯„åˆ†",
                    format="%.1f",
                    width='small'
                ),
                'symbol': st.column_config.TextColumn(
                    'Token',
                    width='small',
                    help="ä»£å¸ç¬¦å·"
                ),
                'price': st.column_config.NumberColumn(
                    'Price',
                    format="$%.4f",
                    width='small',
                    help="å½“å‰å¸‚åœºä»·æ ¼"
                ),
                'liquidity': st.column_config.ProgressColumn(
                    'Liquidity',
                    help="æµåŠ¨æ€§è¯„åˆ† (0-100)",
                    format="%.1f",
                    min_value=0,
                    max_value=100
                ),
                'confidence': st.column_config.SelectboxColumn(
                    'Confidence',
                    help="ä»·æ ¼ä¿¡å¿ƒç­‰çº§",
                    options=['low', 'medium', 'high'],
                    width='small'
                ),
                'explorer': st.column_config.LinkColumn(
                    'Explorer',
                    help="åŒºå—é“¾æµè§ˆå™¨é“¾æ¥",
                    width='medium'
                )
            },
            column_order=['score', 'symbol', 'price', 'liquidity', 'confidence', 'explorer'],
            height=table_height,
            use_container_width=True,
            hide_index=True,
            key="live_results_table"
        )
        
        # å®æ—¶ç»Ÿè®¡æŒ‡æ ‡
        cols = st.columns(3)
        with cols[0]:
            st.metric("Avg Score", f"{df['score'].mean():.1f}")
        with cols[1]:
            st.metric("Top Score", f"{df['score'].max():.1f}")
        with cols[2]:
            st.metric("High Conf", df[df['confidence'] == 'high'].shape[0])

    def render_main(self):
        if st.session_state.analysis.get('running', False):
            self.manager.process_tokens()

if __name__ == "__main__":
    analyzer = TokenAnalyzer()
    ui = UIManager(analyzer)
    ui.render_sidebar()
    ui.render_main()
